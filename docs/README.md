# LLM-as-a-Judge Documentation

Welcome to the comprehensive documentation for the LLM-as-a-Judge system!

## 🎯 Quick Navigation

### I want to...

| **Get started quickly** | **[Getting Started](getting-started/README.md)** |
|-------------------------|---------------------------------------------------|
| **Understand the system** | **[System Overview](overview/README.md)** |
| **Use the API** | **[API Reference](api/README.md)** |
| **Configure the system** | **[Configuration Guide](configuration/README.md)** |
| **Develop features** | **[Development Guide](development/README.md)** |
| **Run tests** | **[Testing Guide](testing/README.md)** |
| **Deploy the system** | **[Deployment Guide](deployment/README.md)** |
| **See examples** | **[Examples and Tutorials](examples/README.md)** |

## 📚 Documentation Structure

```
docs/
├── getting-started/          # 🚀 Quick start and basic usage
├── overview/                # 🎯 System overview and concepts
├── api/                     # 📖 API documentation
├── configuration/           # ⚙️ Configuration and setup
├── architecture/            # 🏗️ System architecture
├── development/             # 👨‍💻 Development guides
├── testing/                 # 🧪 Testing documentation
├── deployment/              # 🚀 Deployment and operations
└── examples/                # 💡 Examples and tutorials
```

## 🚀 Quick Start Paths

### I'm new to the project
```
Getting Started → System Overview → First Steps → Examples
```

### I want to use the API
```
API Reference → Examples → Configuration → Getting Started
```

### I want to contribute
```
Development Guide → Testing Guide → Contributing Guidelines
```

### I want to deploy
```
Deployment Guide → Configuration → Architecture
```

## 🎯 Key Features

### Multi-Criteria Evaluation
- **7 evaluation criteria**: accuracy, completeness, clarity, relevance, helpfulness, coherence, appropriateness
- **Weighted scoring system**: Configurable weights for each criterion
- **Rich statistical analysis**: Mean, median, standard deviation, confidence intervals
- **Detailed qualitative feedback**: Strengths, weaknesses, and improvement suggestions

### Advanced Capabilities
- **Structured output support**: Guaranteed JSON structure across all providers
- **Batch processing**: Efficient handling of multiple evaluations
- **Custom criteria**: Define domain-specific evaluation dimensions
- **Robust error handling**: Comprehensive error classification and recovery

## 🧪 Testing

The system includes a comprehensive test suite:

- **Total Tests**: 236+ tests
- **Success Rate**: 100% (all tests passing)
- **Coverage**: Comprehensive coverage across all components

## 🆘 Getting Help

### Documentation
- **FAQ**: Check the [System Overview](overview/README.md#faq) for common questions
- **Examples**: See [Examples and Tutorials](examples/README.md) for practical usage
- **API Reference**: Complete [API documentation](api/README.md) with examples

### Support
- **GitHub Issues**: [Open an issue](https://github.com/superluminal-jp/llm-as-a-judge/issues) for bug reports
- **GitHub Discussions**: [Community discussions](https://github.com/superluminal-jp/llm-as-a-judge/discussions) for questions

---

**Ready to get started?** Check out the [Getting Started Guide](getting-started/README.md)!
