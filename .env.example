# LLM-as-a-Judge Environment Configuration Template
# Copy this file to .env and fill in your actual values

# =============================================================================
# LLM Provider API Keys
# =============================================================================
# AWS Bedrock Configuration
# Get AWS credentials from: https://console.aws.amazon.com/iam/
AWS_ACCESS_KEY_ID=your-aws-access-key-id
AWS_SECRET_ACCESS_KEY=your-aws-secret-access-key
AWS_SESSION_TOKEN=your-aws-session-token-if-using-temporary-credentials
AWS_REGION=us-east-1

# Get your OpenAI API key from: https://platform.openai.com/account/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Get your Anthropic API key from: https://console.anthropic.com/account/keys
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# =============================================================================
# Provider Configuration
# =============================================================================
# Default provider to use (openai, anthropic, or bedrock)
DEFAULT_PROVIDER=anthropic

# Model Configuration
OPENAI_MODEL=gpt-4
ANTHROPIC_MODEL=claude-sonnet-4-20250514
BEDROCK_MODEL=amazon.nova-premier-v1:0
# amazon.nova-premier-v1:0
# anthropic.claude-opus-4-1-20250805-v1:0

# =============================================================================
# Request Configuration
# =============================================================================
# Timeout values in seconds
REQUEST_TIMEOUT=30
CONNECT_TIMEOUT=10

# =============================================================================
# Logging Configuration
# =============================================================================
# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Enable development mode features
DEV_MODE=false
